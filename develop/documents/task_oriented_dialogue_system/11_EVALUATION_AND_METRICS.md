
# 11 EVALUATION AND METRICS

## 1. 評価の全体方針 (Evaluation Framework)


| 区分 | 評価対象 | 目的 | 手法 | 指標 |
| --- | --- | --- | --- | --- |
| **A. オフライン評価** | **システム全体** | リリース前の品質保証（回帰テスト） | Golden Setを用いたシナリオ完遂テスト | 正確性(タスク達成率/正解率) |
|  | **NLU（意図認識）** | 意図認識の単体性能測定 | ラベル付きデータを用いた正解率計測 | 正解率 |
|  | **スロット充填** | スロット充填の単体性能測定 | ラベル付きデータを用いた正解率計測 | F1 Score |
| **B. オンライン評価** | **主観指標（ユーザ）** | ユーザ満足度の測定 | ユーザによる評価フィードバック | アンケート評価 |

※対話システムの場合はシナリオにおける固定メッセージが多いため、返答文の質に関する機械的な判定は用意せず、主観評価のみとする。

---

## 2. オフライン評価 (Offline Evaluation)

開発・変更時に、固定されたテストセット（Golden Set）を用いて実施する。文脈を固定できるため、変更前後の比較が可能。

### 2.1 システムレベル評価（シナリオテスト）

定義されたシナリオ（対話の流れ）をEnd-to-Endで通し、最終的な出力や状態を評価する。

* **Task Success Rate (タスク達成率)**: シナリオが正常完了したか。
* **Response Accuracy (応答正解率)**: システムの最終発話や提示情報が、期待される内容（必須キーワードを含む）と一致するか。

### 2.2 モジュール評価（内部AI機能の評価）

「意図判定」や「スロット抽出」など、パイプラインの各構成要素（モジュール）ごとの精度を評価する。

* **言語理解 (NLU) 評価**
  * **Intent Accuracy (意図判定正解率)**: `intent_type` が正解ラベルと一致した割合。特に `OOS` (Out of Scope) や `SMALL_TALK` の誤判定を監視する。

* **スロット充填 評価**
  * **Slot F1 Score**: スロット抽出の適合率(Precision)と再現率(Recall)の調和平均。抽出漏れと過剰抽出の両方を評価。

---

## 3. オンライン評価 (Online Evaluation)

実際にユーザが操作して評価する。

### 3.1 主観評価指標（ユーザフィードバック）

実際のユーザ満足度（User Satisfaction）を評価。アンケートにより評価する予定。

* ※項目等は別途検討


---

## 4. Test Sets & Workflow (テストセットと運用)

### 4.1 Golden Set (回帰テスト用データ)

オフライン評価用に、以下のJSON形式データを整備・拡張し続けます。

```json
{
  "case_id": "TASK_001_HAPPY_PATH",
  "category": "TASK/STEP_BY_STEP",
  "input_turns": ["予約したい", "東京で", "明日"],
  "expected": {
    "final_intent": "reserve_hotel",
    "final_slots": {"place": "東京", "date": "明日"},
    "dialogue_mode": "CONFIRMATION",
    "must_include": ["承知しました", "予約を実行"],
    "success": true
  }
}

```
